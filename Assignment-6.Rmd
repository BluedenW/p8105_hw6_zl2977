---
title: "Assignment 6"
author: "Zhourong Li zl2977"
date: "2020/12/7"
output: github_document
---

```{r setup, include=FALSE}

library(modelr)
library(tidyverse)
set.seed(50)

knitr::opts_chunk$set(
 echo = TRUE,
 warning = F,   
 message = F,
 fig.width = 12,
 fig.height = 8,
 # fig.asp = 0.618,
 out.width = "90%")

theme_set(theme_minimal() +
  theme(legend.position = "bottom",
  plot.title = element_text(hjust = 0.5, size = 15),
  plot.subtitle = element_text(hjust = 0.5, size = 12)))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_color_viridis_d
scale_fill_discrete = scale_fill_viridis_d

```


## Problem 1

```{r}
homicide_df = 
  read_csv("data/homicide-data.csv", na = c("", "NA", "Unknown")) %>% 
  mutate(
    city_state = str_c(city, state, sep = ", "),
    victim_age = as.numeric(victim_age),
    resolution = case_when(
      disposition == "Closed without arrest" ~ 0,
      disposition == "Open/No arrest"        ~ 0,
      disposition == "Closed by arrest"      ~ 1)
  ) %>% 
  filter(
    victim_race %in% c("White", "Black"),
    city_state != "Tulsa, AL") %>% 
  select(city_state, resolution, victim_age, victim_race, victim_sex)
```


Start with one city.

```{r}
baltimore_df =
  homicide_df %>% 
  filter(city_state == "Baltimore, MD")

glm(resolution ~ victim_age + victim_race + victim_sex, 
    data = baltimore_df,
    family = binomial()) %>% 
  broom::tidy() %>% 
  mutate(
    OR = exp(estimate),
    CI_lower = exp(estimate - 1.96 * std.error),
    CI_upper = exp(estimate + 1.96 * std.error)
  ) %>% 
  select(term, OR, starts_with("CI")) %>% 
  knitr::kable(digits = 3)
```


Try this across cities.

```{r}
models_results_df = 
  homicide_df %>% 
  nest(data = -city_state) %>% 
  mutate(
    models = 
      map(.x = data, ~glm(resolution ~ victim_age + victim_race + victim_sex, data = .x, family = binomial())),
    results = map(models, broom::tidy)
  ) %>% 
  select(city_state, results) %>% 
  unnest(results) %>% 
  mutate(
    OR = exp(estimate),
    CI_lower = exp(estimate - 1.96 * std.error),
    CI_upper = exp(estimate + 1.96 * std.error)
  ) %>% 
  select(city_state, term, OR, starts_with("CI")) 
```

```{r}
models_results_df %>% 
  filter(term == "victim_sexMale") %>% 
  mutate(city_state = fct_reorder(city_state, OR)) %>% 
  ggplot(aes(x = city_state, y = OR)) + 
  geom_point() + 
  geom_errorbar(aes(ymin = CI_lower, ymax = CI_upper)) + 
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

## Problem 2

Load and clean the data for regression analysis.

```{r}
birthweight = read_csv("./data/birthweight.csv") %>%
  janitor::clean_names() %>%
  mutate(
    babysex = factor(babysex),
    babysex = fct_recode(babysex, male = "1", female = "2"),
    frace = factor(frace),
    frace = fct_recode(frace, white = "1", black = "2", asian = "3", puerto_rican = "4", other = "8"),
    mrace = factor(mrace),
    mrace = fct_recode(mrace, white = "1", black = "2", asian = "3", puerto_rican = "4", other = "8"),
    malform = factor(malform),
    malform = fct_recode(malform, absent = "0", present = "1"),
    
  )

sum(is.na(birthweight))
```
We have cleaned the data and converted `babysex`, `frace`, `mrace` and `malform` into factors. There are no missing values in the dataset. The dataset contains `r nrow(birthweight)` rows and `r ncol(birthweight)` columns. I will use stepwise selection to find the best regression model for birthweight, with AIC as the criteria.

```{r}
lm_proposed = lm(bwt ~., data = birthweight)
step_lm=step(lm_proposed, direction = 'both')
summary(step_lm)
```
From the stepwise selection we get the best model with formula = bwt ~ babysex + bhead + blength + delwt + fincome + gaweeks + mheight + mrace + parity + ppwt + smoken, with adjusted r-squared value of 0.7173 and the p-value of overall F-test is smaller than 2.2e-16, which is statistically significant (less than 0.05).

We draw a plot of residuals vs. fitted values.
```{r}
birthweight %>% 
  add_predictions(model = step_lm, var = "pred") %>% 
  add_residuals(model = step_lm, var = "resid") %>%
  ggplot(aes(x = pred, y = resid)) + 
  geom_point(alpha = 0.5, color = "blue") +
  geom_smooth(se = F, color = "red", method = "lm") + 
  labs(title = "Model residuals vs. Fitted values", 
       y = "Residuals",
       x = "Fitted Value")
```
        
From the above plot, we can see there are some very small predictions on the left side of the plot, and the residuals on the left side of the plot are not distributed normally (most residuals on the left have positive values). While most of the predictions are distributed evenly (constant variance) around the 0 line on the right side of the plot. This model seems not fitted quite well.

Compare my model to two others. `model1` is the main effects only model `bwt ~ blength + gaweeks`, and `model_2` is using head circumference, length, sex, and all interactions (including the three-way interaction) between these, `bwt ~ bhead * blength * babysex`.

```{r}
cross_cv = 
    crossv_mc(birthweight, 100) %>% 
    mutate(
        model_1 = map(train, ~lm(bwt ~ blength + gaweeks, data = .x)),
        model_2 = map(train, ~lm(bwt ~ bhead * blength * babysex, data = .x)),
        model_fit = map(train, ~lm(bwt ~ babysex + bhead + blength + delwt + fincome + gaweeks + mheight + mrace + parity + ppwt + smoken, data = .x))) %>%
    mutate(
    rmse_model1 = map2_dbl(model_1, test, rmse),
    rmse_model2 = map2_dbl(model_2, test, rmse),
    rmse_modelfit = map2_dbl(model_fit, test, rmse)) 
  
comparison_df = cross_cv %>%
  select(starts_with("rmse")) %>%
  pivot_longer(everything(),
               names_to = "model",
               values_to = "rmse",
               names_prefix = "rmse_") %>%
  mutate(
    model = fct_inorder(model)) 

  comparison_df  %>%
  ggplot(aes(x = model, y = rmse, fill =model)) +
  geom_violin() +
  labs(x = "Models", y = "rmse", title = "Distribution of RMSE Values for each Model")
  
```
     
From the above violin plot of RMSE, we can see my fitted model `modelfit` outperforms other two models. Moreover, `model2` including three way interactions performs better comparing with the main effects only model `model1`.

## Problem 3

```{r}
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2017-01-01",
    date_max = "2017-12-31") %>%
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) %>%
  select(name, id, everything())
```

```{r}

r2_data = 
weather_df %>%
 modelr::bootstrap(n = 1000) %>%
 mutate(
   models = map(strap, ~lm(tmax ~ tmin, data = .x)),
   results_r2 = map(models, broom::glance)) %>%
 select(-strap, -models) %>%
 unnest(results_r2) 

log_data =
 weather_df %>%
 modelr::bootstrap(n = 5000) %>%
 mutate(
   models = map(strap, ~lm(tmax ~ tmin, data = .x)),
   results_log = map(models, broom::tidy)) %>%
 select(-strap, -models) %>%
 unnest(results_log) %>% 
 select(id = `.id` , term, estimate) %>%
 pivot_wider(
   names_from = term,
   values_from = estimate) %>%
   rename(
    beta_0 = "(Intercept)",
    beta_1 = "tmin"
   ) %>%
 mutate(log_result = log(beta_0*beta_1)) 
```

```{r}
r2_data %>%
 ggplot(aes(x = r.squared)) +
 geom_density(fill = "blue", color = "pink", alpha = .7, size = 1.1) + 
 labs(
   x = "r - squared",
   y = "density",
   title = "Distribution of r-squared Estimates",
   caption = "Results from 5000 Sample Bootstrap"
 )
```
The distribution of `r_hat^2` is roughly close to a normal distribution. However, the distribution is a little skewed and there are some outliers. 

```{r}   
log_data %>%
 ggplot(aes(x = log_result)) +
 geom_density(fill = "green", color = "pink", alpha = .7, size = 1.1) +
  labs(
   x = "log(beta0_hat * beta1_hat)",
   y = "density",
   title = "Distribution of log(beta0_hat * beta1_hat) Estimates",
   caption = "Results from 5000 Sample Bootstrap"
 )

```
The distribution of `log(beta0_hat * beta1_hat)` is also roughly close to a normal distribution. Again, the distribution is a little skewed and there are some outliers. 

We now identify the 2.5% and 97.5% quantiles to provide a 95% confidence interval for these two quantities.

```{r}
quantile(r2_data$r.squared, c(.025, .975))%>%
  knitr::kable(col.name = c("R-Squared"), digits = 4)
```

From the above table, the 95% confidence interval for R-Squared is (0.8962, 0.9269).

```{r}
quantile(log_data$log_result,c(.025, .975))%>%
  knitr::kable(col.name = c("log(beta0_hat * beta1_hat)"), digits = 4)
```

From the above table, the 95% confidence interval for log(beta0_hat * beta1_hat) is (1.9656, 2.059).